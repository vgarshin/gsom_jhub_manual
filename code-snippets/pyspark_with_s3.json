{
  "display_name": "PySpark with S3",
  "metadata": {
    "tags": [
      "spark",
      "s3"
    ],
    "description": "Start Spark session with object storage connect",
    "display_name": "PySpark with S3",
    "code": [
      "from pyspark import SparkContext, SparkConf",
      "from pyspark.sql import SparkSession",
      "",
      "# web UI for the Spark",
      "",
      "def uiWebUrl(self):",
      "    from urllib.parse import urlparse",
      "    web_url = self._jsc.sc().uiWebUrl().get()",
      "    port = urlparse(web_url).port",
      "    return '{}proxy/{}/jobs/'.format(os.environ['JUPYTERHUB_SERVICE_PREFIX'], port)",
      "",
      "SparkContext.uiWebUrl = property(uiWebUrl)",
      "",
      "# Spark settings",
      "conf = SparkConf()",
      "conf.set('spark.master', 'local[*]')",
      "conf.set('spark.driver.memory', '16G')",
      "conf.set('spark.driver.maxResultSize', '4G')",
      "# use line below for ClickHouse connection from Spark",
      "# variable `CLICKHOUSE_JAR` is a path to jar file with driver ",
      "# e.g. `CLICKHOUSE_JAR = 'jars/clickhouse-jdbc-0.4.0-shaded.jar'`",
      "#conf.set('spark.driver.extraClassPath', CLICKHOUSE_JAR) \\",
      "sc = SparkContext(conf=conf)",
      "spark = SparkSession(sc)",
      "",
      "# Spark's access for object storage settings",
      "spark._jsc.hadoopConfiguration().set('fs.s3a.access.key', creds['aws_access_key_id'])",
      "spark._jsc.hadoopConfiguration().set('fs.s3a.secret.key', creds['aws_secret_access_key'])",
      "spark._jsc.hadoopConfiguration().set('fs.s3a.impl','org.apache.hadoop.fs.s3a.S3AFileSystem')",
      "spark._jsc.hadoopConfiguration().set('fs.s3a.multipart.size', '104857600')",
      "spark._jsc.hadoopConfiguration().set('fs.s3a.block.size', '33554432')",
      "spark._jsc.hadoopConfiguration().set('fs.s3a.threads.max', '256')",
      "spark._jsc.hadoopConfiguration().set('fs.s3a.endpoint', 'http://storage.yandexcloud.net')",
      "spark._jsc.hadoopConfiguration().set('fs.s3a.aws.credentials.provider', ",
      "                                     'org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider')",
      "",
      "spark"
    ],
    "language": "Python"
  },
  "schema_name": "code-snippet"
}